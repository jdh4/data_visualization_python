{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "vscode": {
      "interpreter": {
        "hash": "74a539bb1a30b12322b0673657a3362ba97f8c77e4e9b57fd18ae9f35996046a"
      }
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "\n# Data Visualization in Python\n\n*Workshop material originally created by Michal Grzadkowski and Brian Arnold. Modified slightly by Jake Snell and Carolina Roe-Raymond.*\n\nWelcome to the Data Visualization in Python workshop, presented by the [Princeton Institute for Computational Science & Engineering](https://researchcomputing.princeton.edu/about/about-picscie) (PICSciE), [Research Computing](https://researchcomputing.princeton.edu/about),  and [Center for Statistics and Machine Learning](https://csml.princeton.edu/) (CSML) at Princeton University.\n\nDuring this course we will learn how to interact with some of the most powerful Python packages for data visualization.\n\nWe will try to cover a lot and move quickly to show you how to generally use these packages and what's possible.\n\n---",
      "metadata": {
        "id": "VhVYELCSSedt"
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Setting Up\n\nFor making plots we will be using *Matplotlib*, *Seaborn* and *Plotly* if time permits.\n\nWe will also use *Numpy* and *Pandas* for creating and reshaping matrices and data tables, but more on this in a moment.",
      "metadata": {
        "id": "52NjipgjUtKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Intro to Google Colab\n\n*Source*: [Overview of Colaboratory Features](https://colab.research.google.com/notebooks/basic_features_overview.ipynb#scrollTo=d-S-3nYLQSHb)",
      "metadata": {
        "id": "yy8Uengvn-Gd"
      }
    },
    {
      "cell_type": "markdown",
      "source": "#### a. Table of Contents\n\nNote the ability to navigate through this document with the table of contents (shown in sidebar, left-hand side of document).\n\nYou can expand and hide sections as needed.",
      "metadata": {
        "id": "pD7RBaQOpJF8"
      }
    },
    {
      "cell_type": "markdown",
      "source": "#### b. Cells\nA notebook is a list of cells. Cells contain either 1) text or 2) code and its output. Click a cell to select it.",
      "metadata": {
        "id": "JyG45Qk3qQLS"
      }
    },
    {
      "cell_type": "markdown",
      "source": "##### Text cells\nThis is a **text cell**. You can **double-click** to edit this cell. Text cells\nuse markdown syntax.\n\nEnter today's date here, and make it bold:\n\nYou can press **Shift+Enter** to take the cell out of editing mode.\n\nTo learn more on how to use markdown syntax, see the [markdown\nguide](/notebooks/markdown_guide.ipynb).",
      "metadata": {
        "id": "Id6tDF1HQSHD"
      }
    },
    {
      "cell_type": "markdown",
      "source": "##### Code cells\nBelow is a **code cell**. Once the toolbar button indicates CONNECTED, click in the cell to select it and execute the contents in the following ways:\n\n* Click the **Play icon** in the left gutter of the cell;\n* Type **Cmd/Ctrl+Enter** to run the cell in place;",
      "metadata": {
        "id": "KR921S_OQSHG"
      }
    },
    {
      "cell_type": "code",
      "source": "a = 10\nb = 5\nc = a + b\nc",
      "metadata": {
        "id": "xT-hoht_A-ub",
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 1,
          "output_type": "execute_result",
          "data": {
            "text/plain": "15"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": "If something you're trying to run in python is taking a long time, and you want to \"cancel\" it, the python processes can be interrupted. Run the following cell and select **Runtime -> Interrupt execution** (*hotkey: Cmd/Ctrl-M I*) to stop execution.",
      "metadata": {
        "id": "RVuqWUXPQSHa"
      }
    },
    {
      "cell_type": "code",
      "source": "import time\nprint(\"Sleeping\")\ntime.sleep(5) # sleep for a while; interrupt me!\nprint(\"Done Sleeping\")",
      "metadata": {
        "cellView": "both",
        "id": "d-S-3nYLQSHb",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Sleeping\nDone Sleeping\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": "## Why Visualize Your Data?\n\nThere are two main reasons to visualize your data:\n\n1. It helps you **understand** your data in order to make better insights.\n2. It helps you **communicate** your findings to others.\n\nThis workshop will help with both of these goals!\n\n---",
      "metadata": {
        "id": "8Kf2usIxf0wn"
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Numpy\n\nThese packages are not **directly** related to data visualization but are extremely important for data analysis and reshaping data into formats that are used by various plotting functions, allowing us to quickly understand the features of large datasets!\n\n### *Very brief* intro to Numpy:\n- matrix data structures, potentially multidimensional\n- numpy arrays faster + more compact than python lists\n- numpy arrays must be homogenous (e.g. numerical data only!)\n\n\n\n\n",
      "metadata": {
        "id": "cRkuifc7PazR"
      }
    },
    {
      "cell_type": "code",
      "source": "import numpy as np",
      "metadata": {
        "id": "8ixMeHsgKHVN",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Let's make a simple array from a list.",
      "metadata": {
        "id": "iyXxAmCdziMC"
      }
    },
    {
      "cell_type": "code",
      "source": "a = np.array([1, 2, 3, 4])\na",
      "metadata": {
        "id": "hA9LaMbcRDi8",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Or from a list of lists, i.e. a matrix with rows and columns. Note the extra square brackets!\n\n",
      "metadata": {
        "id": "ZDpdUlNCzpcw"
      }
    },
    {
      "cell_type": "code",
      "source": "a = np.array([[1, 2, 3, 4],\n              [5, 6, 7, 8],\n              [9, 10, 11, 12]])\n\n# what is the \"shape\"? Rows and columns.\na.shape",
      "metadata": {
        "id": "OkQ4UOkYRDi8",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "To access numbers inside the array, we can index our matrix with the following structure:  \n\n`matrix[row, column]`\n\nFor example, we can look at **all** elements in the second ROW (the `:` is optional here).",
      "metadata": {
        "id": "llhmhYYJz11A"
      }
    },
    {
      "cell_type": "code",
      "source": "a[1, :]",
      "metadata": {
        "id": "jXuXvFCJRDi8",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "or **all** elements in the second column",
      "metadata": {
        "id": "CQQAx_Hlz7F0"
      }
    },
    {
      "cell_type": "code",
      "source": "a[:, 1]",
      "metadata": {
        "id": "tSmlDs6BRDi9",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We can \"broadcast\" arithmetic operations.",
      "metadata": {
        "id": "wPmHZ11H0KFk"
      }
    },
    {
      "cell_type": "code",
      "source": "a * 2",
      "metadata": {
        "id": "s6xwhHEHRDi9",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Numpy has many useful built-in functions, for example summing across rows or columns.\n\n\n",
      "metadata": {
        "id": "wI1zCbGK0Xp-"
      }
    },
    {
      "cell_type": "markdown",
      "source": "The `sum` function in NumPy uses 'axes' to define which dimensions to operate across. For a 2D array:\n\n*   **axis 0** refers to slicing across **rows**\n    + i.e., operation runs vertically downwards across rows\n*   **axis 1** refers to slicing across **columns**\n    + i.e., operation runs horizontally across columns",
      "metadata": {
        "id": "tfhSM555_TVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": "So to sum down rows:",
      "metadata": {
        "id": "XZSVAP0SBIfV"
      }
    },
    {
      "cell_type": "code",
      "source": "a.sum(axis=0)",
      "metadata": {
        "id": "uxdS12Q1RDi9",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Or to sum across columns:",
      "metadata": {
        "id": "PHEI98pz0cRW"
      }
    },
    {
      "cell_type": "code",
      "source": "a.sum(axis=1)",
      "metadata": {
        "id": "YLc7yyFfRDi9",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "There are **many** other numpy functions that do quickly do complex operations with little code. We barely scratched the surface here. For more, see this [Python for Data Science Cheat Sheet](https://web.itu.edu.tr/iguzel/files/Python_Cheat_Sheets.pdf) or the official [Numpy User Guide](https://numpy.org/doc/stable/user/).",
      "metadata": {
        "id": "e6ZFVcfqRDi9"
      }
    },
    {
      "cell_type": "markdown",
      "source": "---",
      "metadata": {
        "id": "MivIYw_qRDi-"
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Pandas\n- Built on Numpy\n    - Uses more memory, slower indexing\n- *Easy* to use with 2D data tables or spreadsheets with *labeled* columns and rows!\n  - Has simple functions to reshape data, summarize information, and do common/useful tasks\n  - See this [Pandas Cheat Sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf) for an overview of capabilities/functions\n- Reshaping or filtering data with Pandas allows us to pass different pieces of information to plotting functions to understand different features of our data.",
      "metadata": {
        "id": "mS4-dY1dRDi-"
      }
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd",
      "metadata": {
        "id": "K_Z5EqL0HcZJ",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Loading and reshaping data with Pandas\n\nWe can use the *Pandas* function `read_csv` to create a *Pandas DataFrame*. Here we will use a url everyone has access to, but you may simply replace this with a file located on your computer.",
      "metadata": {
        "id": "a435v7NYqiCM"
      }
    },
    {
      "cell_type": "code",
      "source": "url = \"weather.csv\"\ndf = pd.read_csv(url)\n\n# or download locally:\n# !wget https://corgis-edu.github.io/corgis/datasets/csv/weather/weather.csv\n# df = pd.read_csv('./weather.csv')",
      "metadata": {
        "id": "SVUh739-J_ML",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "This dataset contains weather information collected from weather stations accross the US from January 2016 to January 2017.\n\nWe can learn much about these data using *Pandas* built-in functions to interact with this DataFrame.\n\nLet's peek at the first 3 lines of the Data Frame with `.head()` and the column names with `.column`.",
      "metadata": {
        "id": "eVC5SVamRDi-"
      }
    },
    {
      "cell_type": "code",
      "source": "df.head(3)",
      "metadata": {
        "id": "GBrl4gHARDi_",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "For huge datasets with many columns that can't all be displayed on the screen, it may easier to just look at the columns.",
      "metadata": {
        "id": "muwX80PW1bMQ"
      }
    },
    {
      "cell_type": "code",
      "source": "df.columns",
      "metadata": {
        "id": "TE_QLbPKRDi_",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We can also ask Pandas to generate some descriptive statistics using `.decribe()`.",
      "metadata": {
        "id": "cqopWLMSf0wv"
      }
    },
    {
      "cell_type": "code",
      "source": "df.describe()",
      "metadata": {
        "id": "kW37jpuEf0wv",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We can remove the whitespaces (\" \") or dots (\".\") from our column names and replace them with underscores (\"_\"). This makes downstream analyses with DataFrames much easier!",
      "metadata": {
        "id": "EVq_Z5HZRDi_"
      }
    },
    {
      "cell_type": "code",
      "source": "df.columns = [col.replace('.', '_').replace(' ', '_') for col in df.columns]\n\n# OR, the less pythonic, longer way to do it for those not familiar with list comprehensions:\n#new_col_names = []\n#for col in df.columns:\n#  new_name = col.replace('.', '_').replace(' ', '_')\n#  new_col_names.append( new_name )\n#df.columns = new_col_names\ndf.columns\n",
      "metadata": {
        "id": "3zfV-h54RDi_",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We can access columns **by name** using square brackets.",
      "metadata": {
        "id": "HhPYGyorUMwT"
      }
    },
    {
      "cell_type": "code",
      "source": "df['Data_Wind_Direction']",
      "metadata": {
        "id": "KiUyayxZRDjA",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Or using dot notation (which autocompletes in Jupyter notebooks, very useful!)\n\nNote: we **had** to change column names for this to work, as they originally contained \".\" which has a specific meaning in python. This approach is nice because it auto-completes in Jupyter notebooks!",
      "metadata": {
        "id": "4G_znFt8UScm"
      }
    },
    {
      "cell_type": "code",
      "source": "df.Data_Wind_Direction",
      "metadata": {
        "id": "Jn7gMJz0RDjA",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We can check the unique entries of each column using the `.unique()` method.\n\n",
      "metadata": {
        "id": "aYLW6j7QLA7Y"
      }
    },
    {
      "cell_type": "code",
      "source": "print(df.Station_State.unique())\nprint(len(df.Station_State.unique()))",
      "metadata": {
        "id": "6PfGGF48K_Sr",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "There should be 51 entries here (50 states + Puerto Rico), but this quick check shows Virginia and Delaware are represented both by their full names and their 2-letter abbreviations. Pandas functions and plotting (below) allow us to quickly do many sanity checks!\n\nLet's confirm this by looking at the rows in which the State is VA instead of Virginia.\n\nThe `.loc` is used to access a group of rows and columns by label(s) or a boolean array.",
      "metadata": {
        "id": "z0_Afh9ORDjA"
      }
    },
    {
      "cell_type": "code",
      "source": "condition = df.Station_State == 'VA' # this is a Series of True/False statements\ndf.loc[condition].head(5) # select rows that correspond to True in 'condition' Series\n# or simply\n#df.loc[df.Station_State == 'VA'].head(5)",
      "metadata": {
        "id": "8u6TjB3OuMrV",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We can rename the Station_State of *DE* and *VA* to *Delaware* and *Virginia*, respectively, using the `.replace()` method of Pandas DataFrames.",
      "metadata": {
        "id": "-m-PshmT0ikg"
      }
    },
    {
      "cell_type": "code",
      "source": "df = df.replace(to_replace={'Station_State': 'DE'}, value={'Station_State': 'Delaware'}, regex=True)\ndf = df.replace(to_replace={'Station_State': 'VA'}, value={'Station_State': 'Virginia'}, regex=True)",
      "metadata": {
        "id": "fj5a9RoE08Ob",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Lets check again the number of unique entries in the *Station_State* column.",
      "metadata": {
        "id": "Twi6fNUx2UCy"
      }
    },
    {
      "cell_type": "code",
      "source": "print('Number of unique states in the dataframe:', len(df.Station_State.unique()))",
      "metadata": {
        "id": "F23d6SBx2SHu",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We will now focus on data visualization, but see the [Pandas documention and tutorials](https://pandas.pydata.org/pandas-docs/stable/index.html) for more information about many other useful functions!\n\nTip: Use Google to search what you want to do with \"pandas\" in the query. Usually the first few search hits will have the answer. Memorization then comes with time.",
      "metadata": {
        "id": "-Va7VJ1HRDjB"
      }
    },
    {
      "cell_type": "markdown",
      "source": "---",
      "metadata": {
        "id": "7NO7vI6_93Sp"
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Matplotlib\n\n[Matplotlib](http://matplotlib.org/) is one of the most common Python packages for creating 1-D and 2-D plots. Here we will cover how to use Matplotlib to create three of the most widely used plot types for data visualization: line plots, bar plots, and scatter plots. We will also go through an example of how to combine different plot types using the flexibility that the package offers.\n\nWe also encourage you to use the package [documentation](https://matplotlib.org/stable/) and its [examples](https://matplotlib.org/stable/gallery/index.html) for details and inspiration.",
      "metadata": {
        "id": "xNzEBRkzL3B0"
      }
    },
    {
      "cell_type": "markdown",
      "source": "We will start by importing the *Matplotlib* package as:",
      "metadata": {
        "id": "NKCUs5KGf5gd"
      }
    },
    {
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt  # This is equivalent to 'from matplotlib import pyplot as plt'.",
      "metadata": {
        "id": "KVY1GJmff7N1",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We will also just make a few changes to the appearance of our plots:",
      "metadata": {
        "id": "Q-FbEqRugZga"
      }
    },
    {
      "cell_type": "code",
      "source": "plt.rcParams['axes.facecolor'] = 'white'\nplt.rcParams['axes.edgecolor'] = 'white'\nplt.rcParams['savefig.facecolor'] = 'white'\nplt.rcParams['savefig.edgecolor'] = 'white'",
      "metadata": {
        "id": "Yw51fhXHgcTY",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "---",
      "metadata": {
        "id": "7Nbqwym1RaKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Line Plots\n\nThere are essentially two approaches to use Matplotlib:\n\n1. **Function-based Approach**: rely on pyplot to automatically create and manage the figures and axes, and then use pyplot functions for plotting.\n2. **Object-oriented Approach**: explicitly create figures and axes, and call methods on them.\n\nWe will start with a basic example to understand the syntax that is used to create figures in Matplotlib using the **function-based approach**.",
      "metadata": {
        "id": "WALI8x49GUpe"
      }
    },
    {
      "cell_type": "code",
      "source": "# Generate some data.\nx = [0., 2., 3., 4.]\ny = [5., 2., 5., 4.]\n\n# We can make a figure using:\nplt.figure()\n\n# We can then insert a 1D line plot as:\nplt.plot(x, y, color='orange')\n\n# We can set a title using the command:\nplt.title('Simple Plot')\n\n# And show the result using:\nplt.show()",
      "metadata": {
        "id": "ibeyu-Wn_36G",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "---",
      "metadata": {
        "id": "Ds8lLnOCTBjQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": "Now that we know the basics, we can go a bit further and improve our plots using different properties of the functions that are built in *Matplotlib*. For instance, we can add more data or change properties of the plots (e.g. figure size, resolution, colors, line styles...). We will also learn how to save our figures so we can use them in combination with other software such as *Adobe Illustrator®* ([available free to students, faculty, and staff](https://oit.princeton.edu/creativecloud)), *Affinity Designer* or *Inkscape*.",
      "metadata": {
        "id": "s406qpHSgPoA"
      }
    },
    {
      "cell_type": "code",
      "source": "# Create your data.\nx  = [1, 2, 3, 4, 5]\ny1 = [5, 3, 5, 3, 5]\ny2 = [2, 4, 6, 4, 2]\n\n# Create a new figure.\nplt.figure(figsize=(5.0, 3.0), dpi=100)\n\n# Add (overlapping) plots in the figure\n# You can set a name to each series.\nplt.plot(x, y1, label=\"Label A\", color='green')\nplt.plot(x, y2, label=\"Label B\", color='#B2C144', lw=2.0, ls='--')\n\n# Add title, axis labels, legend, etc.\n# (we use LaTeX-style math formatting in the title and y-label)\nplt.title(\"New example \" + r'$\\beta_1$')\nplt.xlabel(\"x axis\", size=12)\nplt.ylabel(r'$\\nu$', size=20)\n\nplt.legend(loc=0)  # Automatic position using 'loc=0' (default).\n\n# Save your figure using plt.savefig('filename.svg').\nplt.savefig('./my_fig2.svg', dpi=300)\n\n# Matplotlib Colors: https://matplotlib.org/stable/gallery/color/named_colors.html\n# Hexadecimal Colors: https://htmlcolorcodes.com/color-picker/\n# LaTeX Math notation: http://tug.ctan.org/info/undergradmath/undergradmath.pdf\n# Matplotlib Linestyles: https://matplotlib.org/stable/gallery/lines_bars_and_markers/linestyles.html",
      "metadata": {
        "id": "08RTGn_xE3MP",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "---",
      "metadata": {
        "id": "SZ4gCA4UTELG"
      }
    },
    {
      "cell_type": "markdown",
      "source": "We can also generate data systematically using a function. Here we will use some built in functions from *Numpy*. We will import *Numpy* using the alias **np** since we will use this package very often.",
      "metadata": {
        "id": "CMLPtYJB9r5W"
      }
    },
    {
      "cell_type": "code",
      "source": "import numpy as np",
      "metadata": {
        "id": "bSrqPio3_CE4",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We can use *Numpy* to generate an array with equally spaced data-points in a certain range using the `np.arange` function. You may also find the parametrization in `np.linspace` more convenient for the same purposes.",
      "metadata": {
        "id": "hTY33WRqASRh"
      }
    },
    {
      "cell_type": "code",
      "source": "x = np.arange(0, 10, 0.1)  # start, end, step size.\nx\n\nx = np.linspace(0, 10, 101) # start, end, step count\nx",
      "metadata": {
        "id": "DmZ0fZNs-2xb",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Then we can pass the generated data a numpy function — in this case, the cosine function. Like most others in Numpy, this function is _vectorized_, meaning that it operates on and returns arrays.",
      "metadata": {
        "id": "zPvlIXNgAfkd"
      }
    },
    {
      "cell_type": "code",
      "source": "y = np.cos(x)\ny",
      "metadata": {
        "id": "eSVbWlKOBKhg",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Now we can use the generated data to plot the $\\cos(a)$ function.",
      "metadata": {
        "id": "p34exuB2BtcQ"
      }
    },
    {
      "cell_type": "code",
      "source": "plt.figure()\nplt.plot(x, y)",
      "metadata": {
        "id": "cqO9sQxxBxTQ",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### EXERCISES A",
      "metadata": {
        "id": "ENfwi0kCVxuz"
      }
    },
    {
      "cell_type": "code",
      "source": "# Starting with the plot we generated above (plotting cos(a)):\n# Exercise 1. Set the x axis label to \"a\",  and the y axis label to \"f(a)\".\n# Exercise 2. Change the line color to green and set the linewidth to 2.0.\n# Exercise 3. Add another plot representing sin(a).",
      "metadata": {
        "id": "syebz2ipVu4e",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Subplots\n\nRecap: There are essentially two approaches to use Matplotlib:\n\n1. **Function-based Approach**: rely on pyplot to automatically create and manage the figures and axes, and then use pyplot functions for plotting.\n2. **Object-oriented Approach**: explicitly create figures and axes, and call methods on them.\n\nIn the examples that we showed you before we used the function-based approach, which is simpler and easier to use for small, uncomplicated plots. However, for larger, more involved plots, we prefer the second approach, as it offers far more flexibility.\n\nHere we will start by creating a *figure* and *axes* Object, and then we will use these Objects to draw a plot 1-D Line Plot.",
      "metadata": {
        "id": "5dtgESZXCHzM"
      }
    },
    {
      "cell_type": "code",
      "source": "x  = [1, 2, 3, 4, 5]\ny1 = [5, 3, 5, 3, 5]\ny2 = [2, 4, 6, 4, 2]\n\nfig, ax = plt.subplots()\n\nfig.set_size_inches(8.0, 5.0)\n\nax.plot(x, y1)\nax.plot(x, y2)\n\n# Careful! The syntax changes when using axes Objects in Matplotlib.\n# Before we were using plt.xlabel('xlabel'). Now we need to\n# prefix these calls with \"set_\".\n\nax.set_xlabel('x label')\nax.set_ylabel('y label')\n\nax.set_xlim(1.5, 4.5)\nax.set_ylim(2.0, 6.5)\n\nplt.show()",
      "metadata": {
        "id": "NLDumM7w7gmZ",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Why should we use *axes Objects* then? Well, one of the motivations for creating *axes Objects* is that they offer an intuitive way of generating subplots in a given *figure*.",
      "metadata": {
        "id": "e8N7S9iQ8WdK"
      }
    },
    {
      "cell_type": "code",
      "source": "# Data.\nx1 = [0, 1, 2, 3, 4, 5]\nx2 = [0, 3, 6, 9, 12, 15]\ny1 = [-1, -2, -3, -4, -5, 0]\ny2 = [1, 2, 3, 4, 5, 0]\n\n# Create figure and axes Objects.\nfig, axs = plt.subplots(nrows=1, ncols=2)\n\n# Set figure size.\nfig.set_size_inches(7., 3)\n\n# We can use the index of the subplots to draw specific plots in these axes.\naxs[0].plot(x1, y1, color='orange')  # Axes\n\naxs[1].plot(x2, y2, color='blue')\n\n# We can specify the axis labels in the same way.\naxs[0].set_xlabel('x1')\naxs[0].set_ylabel('y1')\naxs[1].set_xlabel('x2')\naxs[1].set_ylabel('y2')\n",
      "metadata": {
        "id": "T-QbzUaP8faz",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We can even go further and create a grid of plots using the *axis* index notation.",
      "metadata": {
        "id": "oYoS3GU_E6aI"
      }
    },
    {
      "cell_type": "code",
      "source": "fig, axarr = plt.subplots(nrows=2, ncols=2)\naxarr[0][0].plot(x1, y1, 'orange', label='Line A')\naxarr[0][1].plot(x2, y2, 'blue', label='Line B')\naxarr[1][0].plot(x1, y2, 'red', label='Line C')\naxarr[1][1].plot(x2, y1, 'olive', label='Line D')\n\nfig.set_size_inches(5.0, 5.0)\n\nfig.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\nplt.tight_layout()",
      "metadata": {
        "id": "Sk6fdTGSFID2",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We can also add a bit more complexity to our figures by adding a grid with different shape and size to each subplot. For that, we will need to use the `subplot2grid` function.",
      "metadata": {
        "id": "HM2mVvr_O6a9"
      }
    },
    {
      "cell_type": "code",
      "source": "def random_data():\n  x = np.cos(np.linspace(0, 100, 1000))\n  x *= np.random.randint(0, 50, 1)\n  y = np.cos(x) * np.sin(x)\n  return x, y\n\n# Initiate figure\n# ****************************\nfig = plt.figure()\n\n# Create layout grid for plots\n# ****************************\n# define the underlying number of rows and columns for layout\nshape6x2 = (6,2)\n# specify plots and which rows/columns they'll span\nax1 = plt.subplot2grid(shape6x2, (0, 0), rowspan=1, colspan=2)\nax2 = plt.subplot2grid(shape6x2, (1, 0), rowspan=3, colspan=2)\nax3 = plt.subplot2grid(shape6x2, (4, 0), rowspan=2, colspan=1)\nax4 = plt.subplot2grid(shape6x2, (4, 1), rowspan=2, colspan=1)\n\n# Fill plots with data\n# ****************************\nx, y = random_data()\nax1.plot(x, y, color='blue')\n\nx, y = random_data()\nax2.plot(x, y, color='navy')\n\nx, y = random_data()\nax3.plot(x, y, color='purple')\n\nx, y = random_data()\nax4.plot(x, y, color='lightblue')\n\n# Show final layout\n# ****************************\nplt.tight_layout()\nplt.show()",
      "metadata": {
        "id": "_Sg6ByRpPT-O",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "---",
      "metadata": {
        "id": "conKwTNGeS1W"
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Bar Plots",
      "metadata": {
        "id": "9-CelVUmdz8r"
      }
    },
    {
      "cell_type": "markdown",
      "source": "To make bar plots with Function-based Approach:",
      "metadata": {
        "id": "0QmGBEYRheKj"
      }
    },
    {
      "cell_type": "code",
      "source": "x = ['Ruby', 'Python', 'C++', 'Java', 'Perl', 'JavaScript', 'C#', 'PHP']\ny1 = [108065, 103492, 101561, 99951, 99857, 95902, 94653, 93169]\ny2 = [121253, 119082, 101440, 104544, 107698, 117718, 76271, 93828]\n\nplt.figure()\n\nplt.bar(x, y1, label='2017 Average salary (in $)')\nplt.bar(x, y2, label='2020 Average salary (in $)', color='orange', alpha=0.2)\nplt.legend()",
      "metadata": {
        "id": "79C7jc9mv-Ji",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "To make bar plots with Object-oriented-based Approach:",
      "metadata": {
        "id": "kNLgPmLDhiVa"
      }
    },
    {
      "cell_type": "code",
      "source": "fig, ax = plt.subplots(nrows=1, ncols=2)\nfig.set_size_inches(15, 3.)\n\nax[0].bar(x, y1, label='2017')\nax[1].bar(x, y2, label='2020', color='orange')\nax[0].set_title('2017 Average salary (in $)')\nax[1].set_title('2018 Average salary (in $)')\n\nax[0].set_ylim(0, 125e3) # 125e3 --> 125 x 10^3\nax[0].set_ylim(0, 125e3)",
      "metadata": {
        "id": "DzhC3I7XF8mN",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "To create a multiple bar chart:",
      "metadata": {
        "id": "dqmO7ralisZn"
      }
    },
    {
      "cell_type": "code",
      "source": "x_positions = np.arange(0, len(x))\n\nplt.figure(figsize=(12, 3))\n\nplt.bar(x_positions-0.2, y1, width=0.4, label='2017')\nplt.bar(x_positions+0.2, y2, width=0.4, label='2020', color='orange')\n\nplt.xticks(x_positions, labels=x)\n\nplt.legend()\nplt.show()",
      "metadata": {
        "id": "jHI7CgxXMxnU",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "---",
      "metadata": {
        "id": "3hI4WZXSfnk0"
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Scatter Plots\n\n**Note**: Line plots are typically used for representing continuous functions. In contrast, scatter plots are used to show relationships between two sets of data without implicitly stating the ordering and connection between the data-points.\n\nTo create a basic scatter plot, use the `ax.scatter()` method.",
      "metadata": {
        "id": "sIZLTZ0pdo0Z"
      }
    },
    {
      "cell_type": "code",
      "source": "xvals = [0.0, 1.0, 4.3, 2.0, 3.5, 2.5, 0.5, 5.0, 6.0, 7.0]\nyvals = [0.0126, 0.031, 0.072, 0.056, 0.079, 0.068, 0.020, 0.056, 0.031, 0.0125]\n\nfig, ax = plt.subplots()\nfig.set_size_inches(11, 7)\n\nax.scatter(xvals, yvals)",
      "metadata": {
        "id": "bZv4MenQpYOF",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "To plot one point at time:",
      "metadata": {
        "id": "w9N40lQm3gOc"
      }
    },
    {
      "cell_type": "code",
      "source": "import random\n\nfig, ax = plt.subplots()\nfig.set_size_inches(11, 7)\n\nfor _ in range(500):\n  xval = random.gauss(0, 1)\n  yval = 2 * xval + 3 + random.gauss(0, 1.3)\n\n  ax.scatter(xval, yval, s=103, alpha=0.41)\n",
      "metadata": {
        "id": "ChynwZKEiXHR",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "It is often useful to annotate scatter points with information on what a given point represents. For this we can use colours, shapes, labels, etc. In this case, we will use the flexibility of matplotlib to create a scatterpie plot, in which each scatter point is its own pie graph.\n\nFor this we will make use of the `inset_axes` function, which allows us to create a subplot of arbitrary size and position anywhere within an existing plot.",
      "metadata": {
        "id": "4NKcEHxvlEAK"
      }
    },
    {
      "cell_type": "code",
      "source": "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n\nfig, ax = plt.subplots()\nfig.set_size_inches(13, 13)\n\n# fix the randomness so that we can make the same random plot each time\nrandom.seed(3333)\n\nfor _ in range(13):\n  xval = random.gauss(0, 1)\n  yval = 2 * xval + 3 + random.gauss(0, 1.3)\n\n  # choose the proporties of the pie chart\n  pie_clr = random.random(), random.random(), random.random()\n  pie_size = random.uniform(0.5, 2.5)\n  pie_prop = random.uniform(0.1, 0.9)\n\n  # define the area the pie plot will cover by stating its lower-left corner and\n  # its dimensions\n  pie_bbox = (xval - pie_size / 2, yval - pie_size / 2,\n              pie_size, pie_size)\n\n  # create a new axis for the pie chart subplot\n  pie_ax = inset_axes(ax, width='100%', height='100%',\n                      bbox_to_anchor=pie_bbox, bbox_transform=ax.transData,\n                      axes_kwargs=dict(aspect='equal'), borderpad=0)\n\n  # add the pie chart to the subplot\n  pie_ax.pie(x=[pie_prop, 1 - pie_prop],\n             colors=[pie_clr + (0.91, ), pie_clr + (0.41, )],\n             explode=[0.29, 0], startangle=90)\n\n# clean up plot aesthetics\nax.set_xlim(-3, 3)\nax.set_ylim(-5, 13)\nax.grid(lw=0.71, alpha=0.43)\n",
      "metadata": {
        "id": "_pqr5d7IlrWW",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Seaborn\n\n- Often used along with matplotlib\n- Integrates with Pandas and 2D Data Frames\n- Simple syntax, complex plots with statistics: perfect for exploratory data analysis or even publishable figures",
      "metadata": {
        "id": "4J6mS0Myqrwc"
      }
    },
    {
      "cell_type": "code",
      "source": "import piplite\nawait piplite.install('seaborn')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "import seaborn as sns",
      "metadata": {
        "id": "-ANfe8hzRDjI",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Distribution Plots\n\nNow we will use *Seaborn* to analyze our data in a visual manner.\nWe can start by plotting a distribution plot for a given column (e.g. the distribution of the variable *Wind Speed*).",
      "metadata": {
        "id": "Js7xwsNeasm9"
      }
    },
    {
      "cell_type": "code",
      "source": "g = sns.histplot(df['Data_Wind_Speed'])",
      "metadata": {
        "id": "J8vRlmeTa2Xa",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We can select the number of bins to represent our data using the `bins` argument.  We can also set some limits for our plot using the `set` function and the `xlim` argument.",
      "metadata": {
        "id": "oGZhe7rfXYKd"
      }
    },
    {
      "cell_type": "code",
      "source": "g = sns.histplot(df.Data_Wind_Speed, bins=50)\ng.set(xlim=(0, 25))",
      "metadata": {
        "id": "G5LN0wSucTPN",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Very often it's useful to print out the minimum and maximum values for a given column to get an idea of the range of our data.\nOne can use the `sort_values` function to sort the values in ascending order. In addition, we can use the `min` and `max` functions to get the bounds of our data.",
      "metadata": {
        "id": "GqgFrblPX2wn"
      }
    },
    {
      "cell_type": "code",
      "source": "print(df.Data_Wind_Speed.min())\nprint(df.Data_Wind_Speed.max())",
      "metadata": {
        "id": "7Jm1XMVtcl83",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We can filter the values of our dataset, using a conditional statement and create a new dataset with the data that satisfies the criteria that we impose.\nHere, we will create a second dataset (*df2*) with the entries that contain *Wind Speed* values below 25 units.",
      "metadata": {
        "id": "BdhDgwSZYqCp"
      }
    },
    {
      "cell_type": "code",
      "source": "df2 = df[df.Data_Wind_Speed < 25]\nprint(len(df), len(df2))",
      "metadata": {
        "id": "UYu_LqLKdlqX",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We can observe that the maximum *Wind Speed* value in our new subset (*df2*) is below 25 units.",
      "metadata": {
        "id": "oCSd6KhKZKxF"
      }
    },
    {
      "cell_type": "code",
      "source": "df2.Data_Wind_Speed.max()\n# or df[df.Data_Wind_Speed < 25].Data_Wind_Speed.max() if you don't want to create a new data frame",
      "metadata": {
        "id": "GReuepzQZUZa",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Lets plot a new distribuition plot for *Wind Speed* but now using our new subset (*df2*). No need to change axes now!",
      "metadata": {
        "id": "QtAZhSkKZb0X"
      }
    },
    {
      "cell_type": "code",
      "source": "sns.histplot(df2.Data_Wind_Speed, bins=50)\nprint(f\"Average wind speed: {np.average(df2.Data_Wind_Speed):0.4f}\")",
      "metadata": {
        "id": "idVQOvRieklv",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "If we call the method for a histogram more than once, we can plot histograms on top of each other to visualize differences between groups of data.",
      "metadata": {
        "id": "5noLvVMTyEhy"
      }
    },
    {
      "cell_type": "code",
      "source": "# Note we are back to using the full dataset now\nsns.histplot(df.Data_Temperature_Avg_Temp,\n            stat=\"count\",\n            binwidth=5)\nsns.histplot(df.Data_Temperature_Avg_Temp[df.Station_State == \"California\"],\n            stat=\"count\",\n            color=\"orange\",\n            binwidth=5)\nplt.title('Distribution of Average Temperature')\nsns.despine()",
      "metadata": {
        "id": "Q6FrGx3SyK0l",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### EXERCISES B",
      "metadata": {
        "id": "bryMCcZ2YPhs"
      }
    },
    {
      "cell_type": "code",
      "source": "# Let's look at the distribution of the Max. Temperature in the U.S.A. and New Jersey.\n\n# EXERCISE 1. Plot a histogram of the maximum temperature data in the U.S.A. Make the binwidth 10.\n# EXERCISE 2. Overlay a histogram of the maximum temperature data in New Jersey to your previous plot. Make the binwidth 10 as well.\n# EXERCISE 3. Modify the code to use stat=\"density\" so the total area under the histogram is 1.\n# This is useful for comparing distributions!\n",
      "metadata": {
        "id": "jsWkWe3UvqFZ",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "---",
      "metadata": {
        "id": "7nmrmfhl9z4W"
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Joint Plots\n\nWe can also show a Joint plot for two different variables. For instance, `Data_Temperature_Min_Temp` and `Data_Temperature_Max_Temp`.\n\nSeaborn easily generates multi-part plots! Doing this with Matplotlib would require more code.",
      "metadata": {
        "id": "nz4cJJTqLAB6"
      }
    },
    {
      "cell_type": "code",
      "source": "sns.jointplot(data=df,\n                x='Data_Temperature_Min_Temp',\n                y='Data_Temperature_Max_Temp',\n                alpha=0.1)",
      "metadata": {
        "id": "DErW39arwOqB",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "It seems that we have a strange value at the 60/60 position.\nLets interrogate our dataset...",
      "metadata": {
        "id": "FsXEwUvTGvqi"
      }
    },
    {
      "cell_type": "code",
      "source": "df60 = df[(df['Data_Temperature_Max_Temp'] == 60) & (df['Data_Temperature_Min_Temp'] == 60) ]\ndf60.head()\n# Note the use of parentheses to specify more than 1 condition to filter rows",
      "metadata": {
        "id": "N-CmQQq7EBBH",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We realize that some stations in Alaska contain a 60 value for the Avg, Max, Min temperature columns...that's weird – especially if we consider that some temperature recordings were made in January.\nIf we search on the internet we will find out that the average temperature in Alaska in January 2016 was 27°F.\nSo it seems that these entries could potentially be wrong.\n\nThis was a great example to show how visualization tools help to understand and find anomalies in our data.\n\n",
      "metadata": {
        "id": "XhzveHumHFH5"
      }
    },
    {
      "cell_type": "markdown",
      "source": "---",
      "metadata": {
        "id": "aowC96b1KnW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Pair Plots\n\nA _pair plot_ draws a pairwise relationships in a dataset, so one can use it to analyze the distribution of multiple variables at the same time.\n\nWe start by creating a new subset of our data by selecting some columns. For instance we can select the columns that contain temperature information.",
      "metadata": {
        "id": "G4MtJB5-KogW"
      }
    },
    {
      "cell_type": "code",
      "source": "dfTemp = df[['Data_Temperature_Avg_Temp', 'Data_Temperature_Max_Temp', 'Data_Temperature_Min_Temp']]",
      "metadata": {
        "id": "iRLvQDCU9uUS",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Let's take a look to our new subset.",
      "metadata": {
        "id": "ds_Y0jRiZIar"
      }
    },
    {
      "cell_type": "code",
      "source": "dfTemp.head(5)",
      "metadata": {
        "id": "mw4lRonV-nz_",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Now, we can plot a joint plot for each pair of columns in the temperatures subset using the *Seaborn* `pairplot` built-in function.\nNote: this may be computationally expensive.\n",
      "metadata": {
        "id": "SyUfFl2gs1Yf"
      }
    },
    {
      "cell_type": "code",
      "source": "# the 'fivethirtyeight' theme set above doesn't play well with pairplot! Let's revert to defaults!\nplt.rcParams.update(plt.rcParamsDefault)\n%matplotlib inline\n#plt.style.use('seaborn-v0_8-darkgrid')\n\nsns.pairplot(dfTemp, plot_kws={'alpha': 0.5})",
      "metadata": {
        "id": "hwv_La3uC46C",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Since the temperature data above fall into different categories (e.g. from year 2016 or 2017), we can also keep track of these categories with different colors using the hue argument.\n\nCheck color palettes in: https://seaborn.pydata.org/tutorial/color_palettes.html\n",
      "metadata": {
        "id": "-58VYhE_tLRR"
      }
    },
    {
      "cell_type": "code",
      "source": "dfTemp = df[['Date_Year', 'Data_Temperature_Avg_Temp', 'Data_Temperature_Max_Temp', 'Data_Temperature_Min_Temp']]\nsns.pairplot(dfTemp, hue='Date_Year', palette='bright')",
      "metadata": {
        "id": "pceDMVih_pve",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "---",
      "metadata": {
        "id": "1AhoKb7O9_ga"
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Bar Plots\n\nWe can build Bar Plots with the values in our *Pandas* dataframe using the *Seaborn* `barplot` built-in function.\nHere we decide to plot the maximum temperature (see `Data_Temperature_Max_Temp` column) for the different months of the year.",
      "metadata": {
        "id": "G3QRvlQBLUHk"
      }
    },
    {
      "cell_type": "code",
      "source": "sns.barplot(x='Date_Month', y='Data_Temperature_Max_Temp', data=df)",
      "metadata": {
        "id": "2a_mIhDRDz0z",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Note that the *Seaborn* `barplot` function provides (by default) the average values over a given variable. In this example it computes the average of the `Data_Temperature_Max_Temp` values for a given month (these include different weeks, stations, states, ...).\n\nWe can also define specific estimators by passing a function to the `estimator` parameter of the *Seaborn* `barplot` method. For instance, we can ask *Seaborn* to compute the standard deviation of the `Data_Temperature_Max_Temp` values for a given month of the year.",
      "metadata": {
        "id": "Nlfvoh-F-ncO"
      }
    },
    {
      "cell_type": "code",
      "source": "sns.barplot(x='Date_Month', y='Data_Temperature_Max_Temp', data=df, estimator=np.std)",
      "metadata": {
        "id": "YEVfg6fzE2b5",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "---",
      "metadata": {
        "id": "EZVzC5hPLXeB"
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Box Plots\n\nA box plot (or box-and-whisker plot) shows the distribution of data and allows us to compare across levels of a categorical variable. The box shows the quartiles of the dataset while the whiskers extend to show the rest of the distribution, except for points that are determined to be “outliers” using a method that is a function of the inter-quartile range (by default `whis=1.5`, proportion of the IQR past the low and high quartiles to extend the plot whiskers).",
      "metadata": {
        "id": "RK8RTDPuGhde"
      }
    },
    {
      "cell_type": "code",
      "source": "sns.boxplot(x='Date_Month', y='Data_Temperature_Avg_Temp', data=df,\n            whis=1.5)",
      "metadata": {
        "id": "OXG6LsNRFI9U",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "If we pass the `Date_Year` column name to the `hue` argument, we can create box plots that directly compare the distributions across years for each month. We can select a color scheme passing a `palette` argument.\n\nThis is a decently complicated plot created using minimal code!",
      "metadata": {
        "id": "IRIWCr4kysfx"
      }
    },
    {
      "cell_type": "code",
      "source": "sns.boxplot(x='Date_Month', y='Data_Temperature_Avg_Temp',\n            data=df, hue='Date_Year', palette='coolwarm')",
      "metadata": {
        "id": "ZEFEiz2fGdZt",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Here we realize that our dataset is almost limited to data collected in 2016 (in 2017 we only have entries of data-points collected in January).\n\nAgain, representing our data in a visual manner allow us to unravel information about our dataset that we would have missed if we would have only checked the tables.\n",
      "metadata": {
        "id": "e2ciNkU_zHch"
      }
    },
    {
      "cell_type": "markdown",
      "source": "---",
      "metadata": {
        "id": "OyLLj0MDLcmY"
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Violin Plots\n\nViolin plots show similar information as the box plots – showing the distribution of quantitative data in a way that facilitates comparisons between variables or across levels of a categorical variable – but they contain extra information. Violin Plots also show the probability distribution of our data, which is great to check whether our data is skewed.",
      "metadata": {
        "id": "R2ila6Y7LdmZ"
      }
    },
    {
      "cell_type": "code",
      "source": "sns.violinplot(x='Date_Month', y='Data_Temperature_Avg_Temp', data=df)",
      "metadata": {
        "id": "jwQ6dLEGH8Ma",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Here we can also pass `hue` argument to show different series on different sides of the Violin Plots.",
      "metadata": {
        "id": "wsrIcMlccZUy"
      }
    },
    {
      "cell_type": "code",
      "source": "sns.violinplot(x='Date_Month', y='Data_Temperature_Avg_Temp', data=df, hue='Date_Year', split=True)",
      "metadata": {
        "id": "shpy0VinIygi",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "---",
      "metadata": {
        "id": "2mLC67-y8e-0"
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Strip Plots\n\nStrip Plots are useful to see the distribuition of all the observations of one variable at a glance.",
      "metadata": {
        "id": "XGFWdyNv8gNc"
      }
    },
    {
      "cell_type": "code",
      "source": "sns.stripplot(x='Date_Month', y='Data_Temperature_Avg_Temp', hue='Date_Month', palette='husl', legend=False, data=df)",
      "metadata": {
        "id": "5153XjlyKoLT",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "A strip plot can be drawn on its own, but it is also a good complement to box or violin plots – especially for these cases in which showing the underlying distribution of the data is important.",
      "metadata": {
        "id": "6Yc2bCWYVLXm"
      }
    },
    {
      "cell_type": "code",
      "source": "# We can now apply what we learnt from Matplotlib to make a customized plot.\n\nfig, ax = plt.subplots()\nfig.set_size_inches(12, 6)\n\nsns.boxplot(x='Date_Month', y='Data_Temperature_Avg_Temp', data=df, ax=ax, zorder=100)\nsns.stripplot(x='Date_Month', y='Data_Temperature_Avg_Temp', data=df, ax=ax, hue='Date_Month', palette='husl', linewidth=0.5, alpha=0.5)\n\n# We can change the labels of the \"x\" axis.\nax.set_xticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n                    'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\nax.set_xlabel('Month')\nax.set_ylabel('Average Temperature')\n",
      "metadata": {
        "id": "b9pZjGAuK53e",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Exercise. Build a violin plot comparing the Avg. temperature in CA and NJ through the different months of the year.\n\n# Step 1. Create a subset with the data from California and New Jersey.\n# Step 2. Create a figure and axis using Matplotlib using the Object method.\n# Step 3. Plot violin plot using the previous subset and Seaborn.",
      "metadata": {
        "id": "LEp0GlAdWdE0",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Heatmap Plot of a Correlation Matrix\n\nA _heatmap plot_ is a 3-D representations of data in which the data values are represented as colors that represent some numerical scale.\n\nA _correlation matrix_ is a table that shows the correlation coefficients between different variables.  We can visually represent these Correlation Matrices using heatmaps.\n\nHere, we will start by creating a correlation matrix using the precipitation, temperature and wind variables of our dataset.",
      "metadata": {
        "id": "vdZo2sryNNI6"
      }
    },
    {
      "cell_type": "code",
      "source": "df_grid = df[['Data_Precipitation', 'Data_Temperature_Min_Temp',\n              'Data_Temperature_Max_Temp', 'Data_Temperature_Avg_Temp',\n              'Data_Wind_Direction', 'Data_Wind_Speed']]\n\ndata_corr = df_grid.corr()\ndata_corr",
      "metadata": {
        "id": "Wf6lzrc5LMvk",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Now we can pass the Correlation Matrix to the *Seaborn* `heatmap` function in order to get a visual representation of the different values in the matrix.\nWe can even include the values inside corresponding to each column and row by adding passing the argument `annot=True`.",
      "metadata": {
        "id": "eqXGrC5iaWzM"
      }
    },
    {
      "cell_type": "code",
      "source": "sns.heatmap(data_corr, cmap='viridis', linewidths=2.0, linecolor='white',\n            annot=True)",
      "metadata": {
        "id": "n7kF34r-aPgW",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Exercise.\n# Plot in a single figure 3 Heatmap Plots containing the correlation matrices of 3 subsets.\n# Only include precipitation, temperature and wind variables.\n# (Subset 1): only including data from Florida.\n# (Subset 2): only including data from Ohio.\n# (Subset 3): only including data from New York.\n\n# Guideline.\n# Step 1. Create a subset including precipitation, temperature and wind variables using Pandas.\n\n# Step 2. Create the different subsets of the previous subset using Pandas.\n\n# Step 3. Create the correlation matrices for each subset.\n\n# Step 4. Create a figure and axes for each subplot.\n\n# Step 5. Plot the Correlation Heatmaps in each axes.\n\n# Step 6. Set titles for each plot.\n",
      "metadata": {
        "id": "OlhnY8Ll9JFm",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "**Extra (Advanced Usage).** One of the benefits of creating plots using a programming language is the fact that one can automate some tasks that are repeated through the process of creating your figures.",
      "metadata": {
        "id": "zVnAWR_mjZRn"
      }
    },
    {
      "cell_type": "code",
      "source": "df3 = df[['Data_Precipitation', 'Data_Temperature_Min_Temp',\n          'Data_Temperature_Max_Temp', 'Data_Temperature_Avg_Temp',\n          'Data_Wind_Direction', 'Data_Wind_Speed']]\n\nstates = ['California', 'Washington', 'Florida']\n# states = list(df['Station.State'].unique())[0:5]\n\nfig, ax = plt.subplots(nrows=1, ncols=len(states))\nfig.set_size_inches(5 * len(states), 5)\n\nfor i in range(0 , len(states)):\n  subset_i = df3[df['Station_State'] == states[i]]\n  corr_i = subset_i.corr()\n  sns.heatmap(corr_i, cmap='viridis', annot=True, ax=ax[i], cbar=False)\n  ax[i].set_title(states[i])\n\nplt.tight_layout()",
      "metadata": {
        "id": "NRYbl-UsjYc4",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "###A.I. Tools for Generating Matplotlib Code\n\n[Microsoft Copilot](https://copilot.microsoft.com) is a secure, multimodal generative A.I. tool that is available to everyone at Princeton for free. Try using Copilot or your favorite chatbot to generate code for matplotlib figures.\n\nExample prompt and output:\n\n> Generate code for a matplotlib figure with three rows and two columns of subplots using plt.scatter. Include labels for the axes with a font size of 12.",
      "metadata": {
        "id": "WcRVcXYPdocw"
      }
    },
    {
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\nimport numpy as np\n\n# Generate some random data\nx = np.random.rand(100)\ny = np.random.rand(100)\n\n# Create a figure with 3 rows and 2 columns of subplots\nfig, axs = plt.subplots(3, 2, figsize=(10, 15))\n\n# Flatten the array of axes for easy iteration\naxs = axs.flatten()\n\n# Plot scatter plots in each subplot with axis labels\nfor i in range(6):\n    axs[i].scatter(x, y)\n    axs[i].set_title(f'Subplot {i+1}')\n    axs[i].set_xlabel('X-axis', fontsize=12)\n    axs[i].set_ylabel('Y-axis', fontsize=12)\n\n# Adjust layout to prevent overlap\nplt.tight_layout()\n\n# Show the plot\nplt.show()",
      "metadata": {
        "id": "C1IUSgohgeh0",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "**Google Colab A.I. Tool**",
      "metadata": {
        "id": "elWBNkhGiEyl"
      }
    },
    {
      "cell_type": "markdown",
      "source": "One can also use the built-in generative A.I. tool of Google Colab. To do this, create a new code cell and click on \"generate\" in that cell. Using the same prompt as above, the same code is generated:",
      "metadata": {
        "id": "nVzsvIZBhSvZ"
      }
    },
    {
      "cell_type": "code",
      "source": "# prompt: Generate code for a matplotlib figure with three rows and two columns of subplots using plt.scatter. Include labels for the axes with a font size of 12.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Generate some random data\nx = np.random.rand(100)\ny = np.random.rand(100)\n\n# Create a figure with 3 rows and 2 columns of subplots\nfig, axs = plt.subplots(3, 2, figsize=(10, 15))\n\n# Flatten the array of axes for easy iteration\naxs = axs.flatten()\n\n# Plot scatter plots in each subplot with axis labels\nfor i in range(6):\n    axs[i].scatter(x, y)\n    axs[i].set_title(f'Subplot {i+1}')\n    axs[i].set_xlabel('X-axis', fontsize=12)\n    axs[i].set_ylabel('Y-axis', fontsize=12)\n\n# Adjust layout to prevent overlap\nplt.tight_layout()\n\n# Show the plot\nplt.show()\n",
      "metadata": {
        "id": "Q3sdbq5CgvV8",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "**Hopefully you can extrapolate the information that we have covered in this session to your own projects. We will be happy to help you through that process, so please send us an email at visrc@princeton.edu if you have any questions!**\n\n**Before you leave, please fill out the survey for the Data Visualization in Python session. Having feedback from our audience is essential for improving our future bootcamps and workshops. Please complete the survey.**\n\n**Thank you very much!!!**",
      "metadata": {
        "id": "SIbwAYK25lKH"
      }
    }
  ]
}